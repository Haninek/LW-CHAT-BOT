No CSV upload. Use the existing parsed bank statements to:

Produce monthly rows (same fields as our sample CSV) from the analyzer/snapshots.

Expose them via:

GET /api/statements/monthly?deal_id=... ‚Üí JSON rows

GET /api/statements/monthly.csv?deal_id=... ‚Üí CSV download

Frontend fetches JSON, renders the analysis (narrative + dynamic table of all fields), and adds a Download CSV button.

Offer generation uses these rows (exclude wires; safe holdback 8‚Äì12%).

üß± Backend (FastAPI) ‚Äî Add monthly rows + CSV
1) Create a small metrics aggregator

File: server/services/bank_monthly.py (new)

from typing import List, Dict, Any
import re
from decimal import Decimal

# Normalize helpers
def _money(v) -> float:
    try:
        return float(v)
    except Exception:
        try:
            return float(Decimal(str(v)))
        except Exception:
            return 0.0

def _sum(items):
    return float(sum(_money(x) for x in items))

# Categorization by description
PAT_PFSINGLE = re.compile(r'PFSINGLE|SETTLMT\s*PFSINGLE\s*PT|Electronic\s*Settlement', re.I)
PAT_ZELLE    = re.compile(r'\bZELLE\b', re.I)
PAT_AMEX     = re.compile(r'\bAMEX\b', re.I)
PAT_CHASE    = re.compile(r'\bCHASE\b', re.I)
PAT_CADENCE  = re.compile(r'\bCADENCE\b', re.I)
PAT_SBA      = re.compile(r'\bSBA\b|\bEIDL\b', re.I)
PAT_NAV      = re.compile(r'\bNAV\b', re.I)
PAT_RADOV    = re.compile(r'RADOVANOVIC', re.I)
PAT_MCHECK   = re.compile(r'mobile\s*check', re.I)
PAT_WIRE_IN  = re.compile(r'\bWIRE\b', re.I)

def build_monthly_rows(analyzed_payload: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Input: analyzer/snapshot payload with shape like:
      { "statements": [ { "month": "2025-08", "beginning_balance":..., "ending_balance":..., 
                          "transactions":[ { "date":"2025-08-03", "amount": -123.45, "desc":"..." }, ... ],
                          "daily_endings":[...]
                        }, ... ] }
    Output: rows matching our CSV columns.
    """
    out = []
    statements = (analyzed_payload or {}).get("statements", [])
    for st in statements:
        txs = st.get("transactions", [])
        # balances
        beginning = _money(st.get("beginning_balance"))
        ending    = _money(st.get("ending_balance"))
        # daily endings for min/max
        daily = [ _money(x) for x in st.get("daily_endings", []) ]
        min_end = min(daily) if daily else None
        max_end = max(daily) if daily else None

        # deposits vs withdrawals
        deposits   = [ _money(t.get("amount")) for t in txs if _money(t.get("amount")) > 0 ]
        withdrawals= [ abs(_money(t.get("amount"))) for t in txs if _money(t.get("amount")) < 0 ]

        # categories on withdrawals
        def wsum(pat): return _sum([ abs(_money(t["amount"])) for t in txs if _money(t.get("amount")) < 0 and pat.search(t.get("desc","")) ])
        w_pfs   = wsum(PAT_PFSINGLE)
        w_zelle = wsum(PAT_ZELLE)
        w_amex  = wsum(PAT_AMEX)
        w_chase = wsum(PAT_CHASE)
        w_cad   = wsum(PAT_CADENCE)
        w_sba   = wsum(PAT_SBA)
        w_nav   = wsum(PAT_NAV)

        # categories on deposits
        def dsum(pat): return _sum([ _money(t["amount"]) for t in txs if _money(t.get("amount")) > 0 and pat.search(t.get("desc","")) ])
        d_rad   = dsum(PAT_RADOV)
        d_mchk  = dsum(PAT_MCHECK)
        d_wire  = dsum(PAT_WIRE_IN)

        row = {
            "file": st.get("source_file") or st.get("month") or "",
            "period": st.get("period") or None,
            "beginning_balance": beginning,
            "ending_balance": ending,
            "net_change": ending - beginning,

            "total_deposits": _sum(deposits),
            "deposit_count": len(deposits),
            "deposits_from_RADOVANOVIC": d_rad,
            "mobile_check_deposits": d_mchk,
            "wire_credits": d_wire,

            "total_withdrawals": -_sum(withdrawals),  # keep negative to match prior CSV
            "withdrawal_count": len(withdrawals),
            "withdrawals_PFSINGLE_PT": w_pfs,
            "withdrawals_Zelle": w_zelle,
            "withdrawals_AMEX": w_amex,
            "withdrawals_CHASE_CC": w_chase,
            "withdrawals_CADENCE_BANK": w_cad,
            "withdrawals_SBA_EIDL": w_sba,
            "withdrawals_Nav_Technologies": w_nav,

            "min_daily_ending_balance": min_end,
            "max_daily_ending_balance": max_end,
        }
        out.append(row)
    return out

2) Add endpoints

File: server/routes/statements.py (extend)

from fastapi import APIRouter, Depends, HTTPException, Query, Response
from sqlalchemy.orm import Session
from core.database import get_db
from models import MetricsSnapshot
from services.bank_monthly import build_monthly_rows
import csv, io, json

router = APIRouter(prefix="/api/statements", tags=["statements"])

def _latest_snapshot(db: Session, deal_id: str):
    snap = db.query(MetricsSnapshot)\
             .filter(MetricsSnapshot.deal_id == deal_id)\
             .order_by(MetricsSnapshot.created_at.desc())\
             .first()
    if not snap:
        raise HTTPException(status_code=404, detail="No metrics snapshot for this deal")
    # payload might be a dict or JSON string depending on model
    payload = snap.payload if isinstance(snap.payload, dict) else json.loads(snap.payload or "{}")
    return payload

@router.get("/monthly")
async def get_monthly_rows(
    deal_id: str = Query(...),
    db: Session = Depends(get_db),
):
    payload = _latest_snapshot(db, deal_id)
    rows = build_monthly_rows(payload)
    return {"ok": True, "rows": rows}

@router.get("/monthly.csv")
async def download_monthly_csv(
    deal_id: str = Query(...),
    db: Session = Depends(get_db),
):
    payload = _latest_snapshot(db, deal_id)
    rows = build_monthly_rows(payload)
    if not rows:
        raise HTTPException(status_code=404, detail="No data")

    # write CSV
    buf = io.StringIO()
    fieldnames = list(rows[0].keys())
    w = csv.DictWriter(buf, fieldnames=fieldnames)
    w.writeheader()
    for r in rows:
        w.writerow({k: v if v is not None else "" for k,v in r.items()})
    csv_bytes = buf.getvalue().encode("utf-8")

    headers = {
        "Content-Disposition": 'attachment; filename="monthly_summary.csv"',
        "Content-Type": "text/csv; charset=utf-8",
        "Cache-Control": "no-store",
    }
    return Response(content=csv_bytes, headers=headers, media_type="text/csv")


This uses the latest MetricsSnapshot for the deal (created by your upload/parse flow). It converts it to rows and gives both JSON & CSV.

üñ•Ô∏è Frontend (React/Vite) ‚Äî Fetch rows, render narrative + table, add CSV download
1) Types

File: web/src/types/analysis.ts (new)

export type MonthlyCsvRow = {
  file: string
  period?: string | null
  beginning_balance: number
  ending_balance: number
  net_change: number
  total_deposits: number
  deposit_count: number
  deposits_from_RADOVANOVIC?: number
  mobile_check_deposits?: number
  wire_credits?: number
  total_withdrawals: number    // negative per backend
  withdrawal_count?: number
  withdrawals_PFSINGLE_PT?: number
  withdrawals_Zelle?: number
  withdrawals_AMEX?: number
  withdrawals_CHASE_CC?: number
  withdrawals_CADENCE_BANK?: number
  withdrawals_SBA_EIDL?: number
  withdrawals_Nav_Technologies?: number
  min_daily_ending_balance?: number
  max_daily_ending_balance?: number
}

2) API client additions

File: web/src/lib/api.ts
Add methods inside ApiClient:

  async getMonthlyRows(dealId: string) {
    const endpoint = `/api/statements/monthly?deal_id=${encodeURIComponent(dealId)}`
    return this.request<{ ok: boolean; rows: any[] }>(endpoint)
  }
  getMonthlyCsvUrl(dealId: string) {
    const cfg = this.getConfig()
    const base = cfg.baseUrl || ''
    return `${base}/api/statements/monthly.csv?deal_id=${encodeURIComponent(dealId)}`
  }

3) UI components

Use the same components from earlier (we already gave you MonthlySummary and DynamicCsvTable). They display all fields and the narrative.

web/src/components/analysis/MonthlySummary.tsx

web/src/components/analysis/DynamicCsvTable.tsx

(If they‚Äôre not created yet, add them from the earlier brief verbatim.)

4) Wire into Offers Lab

File: web/src/pages/OffersLab.tsx

Add state for the fetched rows:

import type { MonthlyCsvRow } from '@/types/analysis'
const [monthlyRows, setMonthlyRows] = useState<MonthlyCsvRow[]>([])
const [loadingMonthly, setLoadingMonthly] = useState(false)


After parse success (right where you already call handleGenerateOffers() or set metrics), fetch rows:

// after parseResult?.metrics is set and you have dealId:
setLoadingMonthly(true)
try {
  const r = await apiClient.getMonthlyRows(dealId)
  if (r?.success && (r.data as any)?.rows) {
    setMonthlyRows((r.data as any).rows as MonthlyCsvRow[])
  }
} finally {
  setLoadingMonthly(false)
}


Add the Download CSV button and the narrative + table, BEFORE offers:

<div className="bg-white rounded-2xl p-4 shadow-sm border border-slate-200/50">
  <div className="flex items-center justify-between">
    <h3 className="text-lg font-semibold text-slate-900">Monthly Analysis</h3>
    {dealId && (
      <a
        href={apiClient.getMonthlyCsvUrl(dealId)}
        target="_blank"
        rel="noopener noreferrer"
        className="text-sm px-3 py-1.5 rounded-md border bg-slate-50 hover:bg-slate-100"
      >
        Download CSV
      </a>
    )}
  </div>

  {loadingMonthly && <div className="text-sm text-slate-500 mt-2">Loading monthly rows‚Ä¶</div>}

  {!loadingMonthly && monthlyRows.length > 0 && (
    <>
      <MonthlySummary rows={monthlyRows} />
      <div className="mt-4">
        <DynamicCsvTable rowsRaw={
          monthlyRows.map(r => Object.fromEntries(Object.entries(r).map(([k,v]) => [k, String(v ?? '')])))
        } />
      </div>
    </>
  )}
</div>


Offer Overrides: plug monthlyRows into your capacity logic (exclude wires; 8‚Äì12% holdback):

function computeOfferOverridesFromMonthly(rows: MonthlyCsvRow[]) {
  if (!rows?.length) return undefined
  const months = rows.length
  let totalEligible = 0
  let totalDeposits = 0
  let totalMcaOut = 0

  for (const r of rows) {
    const dep = Math.max(0, r.total_deposits || 0)
    const wires = Math.max(0, r.wire_credits || 0)
    const eligible = Math.max(0, dep - wires)
    totalEligible += eligible
    totalDeposits += dep
    totalMcaOut += Math.max(0, r.withdrawals_PFSINGLE_PT || 0)
  }

  const avgEligible = months ? totalEligible / months : 0
  const mcaLoad = totalDeposits ? (totalMcaOut / totalDeposits) : 0
  const holdbackPct = mcaLoad >= 0.9 ? 0.08 : mcaLoad >= 0.8 ? 0.10 : 0.12

  return {
    normalization: { exclude_wires: true, avg_eligible_inflow: avgEligible },
    holdback_cap: holdbackPct,
    factor_tiers: [1.20, 1.30, 1.45],
    remit_frequency: 'daily',
  }
}


Use it in your existing handleGenerateOffers() when you have monthlyRows.

‚úÖ Acceptance Criteria

 After bank statement parsing, the UI automatically shows:

 A Monthly Summary narrative for each month (Deposits / Withdrawals / Balances + flags like heavy MCA load, wires present, other fixed obligations).

 A Dynamic table with all fields exactly matching the backend rows (no manual column list).

 A Download CSV button that downloads the same data from /api/statements/monthly.csv?deal_id=‚Ä¶.

 Offer generation uses normalized average eligible inflow (excludes wires) and caps holdback 8‚Äì12% based on MCA load.

 Works even if OpenAI is off; we still aggregate from the non-GPT parse/fallback.