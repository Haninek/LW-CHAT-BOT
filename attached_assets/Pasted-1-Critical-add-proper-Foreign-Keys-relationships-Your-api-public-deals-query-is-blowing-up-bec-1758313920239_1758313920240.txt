1) Critical: add proper Foreign Keys + relationships

Your /api/public/deals query is blowing up because SQLAlchemy expects relationships between events ↔ deals (and optionally events ↔ merchants) that don’t exist at the DB level. Let’s fix this the right way:

1.1 Patch your models
server/models/event.py
from sqlalchemy import Column, String, DateTime, Text, Index, func, ForeignKey
from sqlalchemy.orm import relationship
from .base import Base

class Event(Base):
    __tablename__ = "events"
    id = Column(String, primary_key=True)

    # NEW: enforce FK links
    tenant_id   = Column(String, index=True, nullable=True)
    merchant_id = Column(String, ForeignKey("merchants.id", ondelete="SET NULL"), index=True, nullable=True)
    deal_id     = Column(String, ForeignKey("deals.id", ondelete="CASCADE"), index=True, nullable=True)

    type      = Column(String, nullable=False)
    data_json = Column(Text, nullable=True)
    created_at = Column(DateTime, server_default=func.now(), nullable=False)

    # NEW: ORM relationships (optional but recommended)
    merchant = relationship("Merchant", back_populates="events")
    deal     = relationship("Deal", back_populates="events")

Index("ix_events_type_created", Event.type, Event.created_at.desc())

server/models/deal.py
from sqlalchemy.orm import relationship
# ...
class Deal(Base):
    __tablename__ = "deals"
    # ...
    status = Column(String, default="open", nullable=False)
    # NEW:
    events = relationship("Event", back_populates="deal", passive_deletes=True)

server/models/merchant.py (or wherever Merchant lives)
from sqlalchemy.orm import relationship
# ...
class Merchant(Base):
    __tablename__ = "merchants"
    # ...
    events = relationship("Event", back_populates="merchant", passive_deletes=True)


ondelete="CASCADE" on deal_id ensures if a deal is removed, its events go with it. ondelete="SET NULL" on merchant_id preserves events even if a merchant record is removed/merged.

1.2 Ensure SQLite enforces FKs (dev on Replit)

SQLite only enforces FKs if PRAGMA foreign_keys=ON. Add this hook to server/core/database.py:

from sqlalchemy import create_engine, event
from sqlalchemy.engine import Engine
from server.core.config import get_settings

settings = get_settings()
engine = create_engine(settings.DATABASE_URL, future=True)

@event.listens_for(Engine, "connect")
def _set_sqlite_pragma(dbapi_connection, connection_record):
    # Turn on FK checks for SQLite dev environment
    if settings.DATABASE_URL.startswith("sqlite"):
        cursor = dbapi_connection.cursor()
        cursor.execute("PRAGMA foreign_keys=ON")
        cursor.close()


(Keep your existing SessionLocal, init_dev_sqlite_if_needed code as is.)

1.3 Add a migration (safe for SQLite/Postgres)

If you’re not using Alembic yet, you can skip to 1.4 Quick query workaround for immediate relief. But the durable fix is to add FKs through a migration (Alembic’s batch mode recreates the table on SQLite).

Create alembic/versions/uwizard_event_fks.py:

from alembic import op
import sqlalchemy as sa

revision = "uwizard_event_fks"
down_revision = None  # set to your last revision id if you have one
branch_labels = None
depends_on = None

def upgrade():
    conn = op.get_bind()
    # Clean up orphaned rows so FK creation doesn't fail
    conn.execute(sa.text("""
        UPDATE events SET merchant_id = NULL
        WHERE merchant_id IS NOT NULL AND merchant_id NOT IN (SELECT id FROM merchants)
    """))
    conn.execute(sa.text("""
        UPDATE events SET deal_id = NULL
        WHERE deal_id IS NOT NULL AND deal_id NOT IN (SELECT id FROM deals)
    """))

    with op.batch_alter_table("events") as b:
        b.create_foreign_key("fk_events_merchant", "merchants", ["merchant_id"], ["id"], ondelete="SET NULL")
        b.create_foreign_key("fk_events_deal", "deals", ["deal_id"], ["id"], ondelete="CASCADE")

def downgrade():
    with op.batch_alter_table("events") as b:
        b.drop_constraint("fk_events_deal", type_="foreignkey")
        b.drop_constraint("fk_events_merchant", type_="foreignkey")


Then in Replit shell (if you’ve configured Alembic):

alembic upgrade head


If you’re not set up for Alembic, add the model changes (1.1) and pragma (1.2) now; do migrations later.

1.4 Quick workaround for /api/public/deals (no FKs required)

If you need it working right now before migrations, change the endpoint to avoid ORM relationship assumptions. Use explicit OUTER JOINs by columns and tolerate missing events.

Example pattern inside server/routes/public.py (or wherever the endpoint lives):

from sqlalchemy import select, func, desc
from sqlalchemy.orm import Session
from server.models import Deal, Event, Merchant

# Latest event per deal via scalar subquery:
sub = (
    select(func.max(Event.created_at))
    .where(Event.deal_id == Deal.id)
    .correlate(Deal)
    .scalar_subquery()
)

q = (
    select(
        Deal.id.label("deal_id"),
        Deal.status,
        Deal.created_at,
        Merchant.legal_name.label("merchant_name"),
        Event.type.label("last_event_type"),
        Event.created_at.label("last_event_at"),
    )
    .join(Merchant, Merchant.id == Deal.merchant_id, isouter=True)
    .join(Event, sa.and_(Event.deal_id == Deal.id, Event.created_at == sub), isouter=True)
    .order_by(desc(Deal.created_at))
    .limit(100)
)
rows = db.execute(q).all()


This does not require FK metadata and won’t crash even if some events.deal_id values are null/invalid. You can keep this query even after adding FKs; it’s efficient and explicit.

2) “One verification pattern may need adjustment” (make this robust)

If this note refers to your e-signature webhook idempotency check (common), replace the LIKE string probe with a JSON extract so it’s deterministic on SQLite and Postgres.

In server/routes/sign.py, change:

exists = db.execute(
    "SELECT 1 FROM events WHERE type='sign.signed' AND data_json LIKE :needle",
    {"needle": f"%{event_id}%"}
).first()


to (SQLite JSON1 & Postgres both OK):

from sqlalchemy import text
exists = db.execute(
    text("SELECT 1 FROM events WHERE type = :t AND json_extract(data_json, '$.event_id') = :eid LIMIT 1"),
    {"t": "sign.signed", "eid": event_id}
).first()


If your DB isn’t compiled with SQLite JSON1 (rare on Replit), fallback to storing event_id in a separate nullable column ext_event_id with a unique index. Quick schema addition:

Add to Event model:
ext_event_id = Column(String, index=True, unique=False, nullable=True)

On insert of a webhook event, set ext_event_id=event_id and check existence by that column.

3) Replit Agent—exact to-do list (copy/paste)
1) Edit models:
   - server/models/event.py: add ForeignKey(...) for merchant_id, deal_id; add relationships.
   - server/models/deal.py: add events relationship; ensure status default="open".
   - server/models/merchant.py: add events relationship.

2) Enforce SQLite FKs:
   - server/core/database.py: add PRAGMA foreign_keys=ON listener.

3) (Optional but recommended) Add Alembic migration:
   - alembic/versions/uwizard_event_fks.py as provided.
   - Run: alembic upgrade head
   - If Alembic not configured, skip for now.

4) Public deals endpoint:
   - Update its query to use explicit OUTER JOINs as shown (works even before FKs).

5) Webhook idempotency verification:
   - In server/routes/sign.py, replace LIKE probe with json_extract(...) query as shown.

6) Run quick checks in Replit shell:
   - curl -sf http://localhost:8000/api/public/deals  # must 200
   - Create a deal, write an event, re-hit public deals — latest event shows
   - Post a test sign webhook twice — second call should be idempotent

Sanity smoke (Replit shell)
# Start server
uvicorn server.main:app --host 0.0.0.0 --port 8000 --reload & sleep 2

# Public deals should not 500
curl -i http://localhost:8000/api/public/deals | head -n 20

# Create a deal quickly (substitute your route/body)
curl -s -X POST http://localhost:8000/api/deals/start \
 -H "Content-Type: application/json" -H "X-Tenant-ID:T1" -H "Idempotency-Key:k1" \
 -d '{"merchant_hint":{"phone":"+15555550123","legal_name":"Test Deli LLC"},"create_if_missing":true}'

# Re-check public deals now shows the new deal
curl -s http://localhost:8000/api/public/deals | jq '.[0]'


If anything still 500’s, paste the traceback (top ~30 lines) and I’ll point you to the exact file/line to tweak.